{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import json\n",
    "import os\n",
    "\n",
    "tabfact_file_path = '/data1/fch123/OTT-QA/table_crawling/data/tabfact_process'\n",
    "corpus = []\n",
    "\n",
    "it = 0\n",
    "for file in os.listdir(tabfact_file_path):\n",
    "    file_path = os.path.join(tabfact_file_path, file)\n",
    "    with open(file_path, 'r') as f:\n",
    "        table = json.load(f)\n",
    "        corpus.append(table['table_text_horizontal'])\n",
    "    it += 1\n",
    "    if (it > 100000):\n",
    "        break\n",
    "\n",
    "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 2671.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/1001 [00:10<06:28,  2.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2745256/3790932294.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdoc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#print(u)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/rank_bm25.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mdoc_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mq_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_freqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n\u001b[1;32m    118\u001b[0m                                                (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/rank_bm25.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mdoc_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mq_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_freqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /\n\u001b[1;32m    118\u001b[0m                                                (q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "query = []\n",
    "it = 0\n",
    "with jsonlines.open('simplified-nq-train.jsonl', 'r') as f:\n",
    "    for i in tqdm(f):\n",
    "        query.append(i['question_text'])\n",
    "        it += 1\n",
    "        if(it > 1000):\n",
    "            break\n",
    "\n",
    "tokenized_query = [doc.split(\" \") for doc in query]\n",
    "\n",
    "print('start')\n",
    "for i in tqdm(tokenized_query):\n",
    "\n",
    "    doc_scores = bm25.get_scores(i)\n",
    "    u = np.argmax(doc_scores)\n",
    "    #print(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['which', 'is', 'the', 'most', 'common', 'use', 'of', 'opt-in', 'e-mail', 'marketing']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"row 1 is : Word is pacifier ; British English meanings is  ; Meanings common to British and American English is something or somebody that brings peace ; American English meanings is rubber teat for babies ( UK : dummy ) . row 2 is : Word is paddle ; British English meanings is a walk through shallow water , especially at the seaside ( US approx . wade , also UK usage ) ; Meanings common to British and American English is an oar used to propel a canoe , kayak or a small boat the action of using such an oar ; American English meanings is to strike a child with a paddle as a form of corporal punishment ( dated usage ) . row 3 is : Word is panda ; British English meanings is ( panda car ) police car ( slang ) ( US : zebra , black - and - white ) ; Meanings common to British and American English is Type of animal , e.g . giant panda , red panda ; American English meanings is  . row 4 is : Word is pantomime ; British English meanings is A form of comedic , usually family oriented musical stage production ; Meanings common to British and American English is  ; American English meanings is silent acting , usu . without props , by mime artist ( UK : mime ) . row 5 is : Word is pants ; British English meanings is underpants ( also briefs or boxers ) of poor quality ( slang ) ( of a situation ) bad , unfortunate ( slang ) . Although refers to trousers in parts of Northern England ; Meanings common to British and American English is  ; American English meanings is Outerwear from the waist to the ankles ( trousers ) * ( wear the pants in the family ) be masculine , be the breadwinner , perform the husband 's role ( derog . ) ( spoken esp . of a wife , usage becoming obsolete ) . row 6 is : Word is paraffin ; British English meanings is kerosene ; Meanings common to British and American English is  ; American English meanings is a waxy fraction of petroleum commonly used to make candles ( UK : paraffin wax ) . row 7 is : Word is paralytic ; British English meanings is extremely drunk ( slang ) ; Meanings common to British and American English is relating to or affected by paralysis ; American English meanings is  . row 8 is : Word is park ; British English meanings is a tract of ground kept in its natural state , about or adjacent to a residence , as for the preservation of game , for walking , riding , or the like ( esp . Scotland ) a pasture or field area for the parking of motor vehicles ( `` a car park `` ) ( sports ) a soccer or rugby field see also country park ; Meanings common to British and American English is outdoor area for recreational uses ( `` Central Park `` , `` Hyde Park `` ) national park ( orig . US ) ; American English meanings is any of various areas designated for certain purposes * , such as amusement park , theme park , industrial park , trailer park , memorial park ( a cemetery ) ( sports ) enclosed ground for ball games , oftenest the baseball park a level valley among the mountains ( as the Rocky Mountains ) ; also , an area of open grassland , or one for cultivation , esp . if among the woods . row 9 is : Word is parking ; British English meanings is  ; Meanings common to British and American English is the act of parking ( a vehicle ) ; American English meanings is To engage in romantic intimacy in a parked vehicle . ( regional ) turf strip between sidewalk and street ( many regional synonyms exist ; there is no standard name ) . row 10 is : Word is parkway ; British English meanings is a railway station with parking areas intended for commuters ; Meanings common to British and American English is  ; American English meanings is generally , an open landscaped limited - access highway ( q.v . ) ( see article ) regional term for parking ( q.v . ) . row 11 is : Word is pass out ; British English meanings is to graduate from a training centre of a disciplined service ( military , police etc . ) ; Meanings common to British and American English is to become unconscious ; to distribute ; American English meanings is  . row 12 is : Word is patience ; British English meanings is any of a family of one - player card games ( US : solitaire , q.v . ) ; Meanings common to British and American English is the quality of being patient ; American English meanings is  . row 13 is : Word is pavement ; British English meanings is a paved strip at the side of a road , reserved for pedestrians ( US : sidewalk ) ; Meanings common to British and American English is  ; American English meanings is the road surface . row 14 is : Word is PC ; British English meanings is police constable ; Meanings common to British and American English is politically correct personal computer other expansions ; American English meanings is  . row 15 is : Word is pecker ; British English meanings is courage or pluck ; literally , chin ( slang , used in the phrase `` keep your pecker up `` , remain cheerful or , literally , `` keep your chin up `` ) ; Meanings common to British and American English is  ; American English meanings is penis ( slang ) . row 16 is : Word is peckish ; British English meanings is slightly hungry * ; Meanings common to British and American English is  ; American English meanings is irritable or angry . row 17 is : Word is peg ; British English meanings is ( n . ) ( often clothes peg ) a wooden or plastic device for fastening laundry on a clothesline ( US : clothespin ) ( v . ) to fasten ( laundry ) on a clothesline ; Meanings common to British and American English is ( n . ) a cylindrical wooden , metal etc . object used to fasten or as a bearing between objects ( v . ) to fix or pin down ( v . ) to hit with a projectile ( v . ) to engage in a sexual practice in which a woman performs anal sex on a man by penetrating the man 's anus with a strap - on dildo ; American English meanings is ( n . ) a throw ( as in baseball ) ( v . ) to identify or classify ( someone as being something ) * . row 18 is : Word is penny ; British English meanings is ( pl . pence , or , when referring to coins , pennies ) 1 / 100 ( formerly , 1 / 240 ) of the pound sterling ( listed here to reflect ordinary usage ) ; Meanings common to British and American English is a small amount usu . in contrast to a larger one ( `` penny wise , pound foolish `` , common phrase in both British and American usage ) ; American English meanings is ( pl . pennies ) a cent ( esp . the coin ) ( penny - ante ) trivial , small - time . row 19 is : Word is period ; British English meanings is  ; Meanings common to British and American English is section of time menstruation row of the periodic table ; American English meanings is punctuation mark used at the end of a sentence ( interj . ) used at the end of a statement to emphasise its finality * ( `` You are not going to that concert , period ! `` ) ( UK : full stop for both senses ) . row 20 is : Word is pint ; British English meanings is 20 imperial fluid ounces ( about 568 ml , 19.2 US fl oz or \\u200b ⁄ US pt ) , pint of beer , lager or cider ( `` Pour us a pint `` ) ; Meanings common to British and American English is  ; American English meanings is 16 US fluid ounces ( about 473 ml , 16.65 imp fl oz or \\u200b ⁄ imp pt ) .\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenized_query[0])\n",
    "bm25.get_top_n(tokenized_query[0], corpus, n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations\n",
      "document_html\n",
      "document_title\n",
      "document_tokens\n",
      "document_url\n",
      "example_id\n",
      "long_answer_candidates\n",
      "question_text\n",
      "question_tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "nq_train_data_path = '/data1/fch123/OTT-QA/data/v1.0/train/'\n",
    "for it, file in enumerate(os.listdir(nq_train_data_path)):\n",
    "    file_path = os.path.join(nq_train_data_path, file)\n",
    "    it_num = int(file.split('-')[-1].split('.')[0])\n",
    "    query = []\n",
    "    query_url = []\n",
    "    num_num = 0\n",
    "    with gzip.open(file_path, 'r') as f:\n",
    "        for i in tqdm(f):\n",
    "            table = json.loads(i)\n",
    "            for k, v in table.items():\n",
    "                print(k)\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "class Cell:\n",
    "    def __init__(self):\n",
    "        self.value_tokens: list[str] = []\n",
    "        self.type: str = \"\"\n",
    "        self.nested_tables: list[Table] = []\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" \".join(self.value_tokens)\n",
    "\n",
    "    def to_dpr_json(self, cell_idx: int):\n",
    "        r = {\"col\": cell_idx}\n",
    "        r[\"value\"] = str(self)\n",
    "        return r\n",
    "\n",
    "\n",
    "class Row:\n",
    "    def __init__(self):\n",
    "        self.cells: list[Cell] = []\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"| \".join([str(c) for c in self.cells])\n",
    "\n",
    "    def visit(self, tokens_function, row_idx: int):\n",
    "        for i, c in enumerate(self.cells):\n",
    "            if c.value_tokens:\n",
    "                tokens_function(c.value_tokens, row_idx, i)\n",
    "\n",
    "    def to_dpr_json(self, row_idx: int):\n",
    "        r = {\"row\": row_idx}\n",
    "        r[\"columns\"] = [c.to_dpr_json(i) for i, c in enumerate(self.cells)]\n",
    "        return r\n",
    "\n",
    "\n",
    "class Table(object):\n",
    "    def __init__(self, caption=\"\"):\n",
    "        self.caption = caption\n",
    "        self.body: list[Row] = []\n",
    "        self.key = None\n",
    "        self.gold_match = False\n",
    "\n",
    "    def __str__(self):\n",
    "        table_str = \"<T>: {}\\n\".format(self.caption)\n",
    "        table_str += \" rows:\\n\"\n",
    "        for i, r in enumerate(self.body):\n",
    "            table_str += \" row #{}: {}\\n\".format(i, str(r))\n",
    "\n",
    "        return table_str\n",
    "\n",
    "    def get_key(self) -> str:\n",
    "        if not self.key:\n",
    "            self.key = str(self)\n",
    "        return self.key\n",
    "\n",
    "    def visit(self, tokens_function, include_caption: bool = False) -> bool:\n",
    "        if include_caption:\n",
    "            tokens_function(self.caption, -1, -1)\n",
    "        for i, r in enumerate(self.body):\n",
    "            r.visit(tokens_function, i)\n",
    "\n",
    "    def to_dpr_json(self):\n",
    "        r = {\n",
    "            \"caption\": self.caption,\n",
    "            \"rows\": [r.to_dpr_json(i) for i, r in enumerate(self.body)],\n",
    "        }\n",
    "        if self.gold_match:\n",
    "            r[\"gold_match\"] = 1\n",
    "        return r\n",
    "\n",
    "\n",
    "class NQTableParser(object):\n",
    "    def __init__(self, tokens, is_html_mask, title):\n",
    "        self.tokens = tokens\n",
    "        self.is_html_mask = is_html_mask\n",
    "        self.max_idx = len(self.tokens)\n",
    "        self.all_tables = []\n",
    "\n",
    "        self.current_table = Table() # = None\n",
    "        self.tables_stack = collections.deque()\n",
    "        self.title = title\n",
    "\n",
    "    def parse(self):\n",
    "        self.all_tables = []\n",
    "        self.tables_stack = collections.deque()\n",
    "\n",
    "        for i in range(self.max_idx):\n",
    "\n",
    "            t = self.tokens[i]\n",
    "\n",
    "            if not self.is_html_mask[i]:\n",
    "                # cell content\n",
    "                self._on_content(t)\n",
    "                continue\n",
    "\n",
    "            if \"<Table\" in t:\n",
    "                self._on_table_start()\n",
    "            elif t == \"</Table>\":\n",
    "                self._on_table_end()\n",
    "            elif \"<Tr\" in t:\n",
    "                self._onRowStart()\n",
    "            elif t == \"</Tr>\":\n",
    "                self._onRowEnd()\n",
    "            elif \"<Td\" in t or \"<Th\" in t:\n",
    "                self._onCellStart()\n",
    "            elif t in [\"</Td>\", \"</Th>\"]:\n",
    "                self._on_cell_end()\n",
    "\n",
    "        return self.all_tables\n",
    "\n",
    "    def _on_table_start(self):\n",
    "        caption = self.title\n",
    "        parent_table = self.current_table\n",
    "        if parent_table:\n",
    "            self.tables_stack.append(parent_table)\n",
    "\n",
    "            caption = parent_table.caption\n",
    "            if parent_table.body and parent_table.body[-1].cells:\n",
    "                current_cell = self.current_table.body[-1].cells[-1]\n",
    "                caption += \" | \" + \" \".join(current_cell.value_tokens)\n",
    "\n",
    "        t = Table()\n",
    "        t.caption = caption\n",
    "        self.current_table = t\n",
    "        self.all_tables.append(t)\n",
    "\n",
    "    def _on_table_end(self):\n",
    "        t = self.current_table\n",
    "        if t:\n",
    "            if self.tables_stack:  # t is a nested table\n",
    "                self.current_table = self.tables_stack.pop()\n",
    "                if self.current_table.body:\n",
    "                    current_cell = self.current_table.body[-1].cells[-1]\n",
    "                    current_cell.nested_tables.append(t)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def _onRowStart(self):\n",
    "        self.current_table.body.append(Row())\n",
    "\n",
    "    def _onRowEnd(self):\n",
    "        pass\n",
    "\n",
    "    def _onCellStart(self):\n",
    "        current_row = self.current_table.body[-1]\n",
    "        current_row.cells.append(Cell())\n",
    "\n",
    "    def _on_cell_end(self):\n",
    "        pass\n",
    "\n",
    "    def _on_content(self, token):\n",
    "        if self.current_table.body:\n",
    "            current_row = self.current_table.body[-1]\n",
    "            current_cell = current_row.cells[-1]\n",
    "            current_cell.value_tokens.append(token)\n",
    "        else:  # tokens outside of row/cells. Just append to the table caption.\n",
    "            self.current_table.caption += \" \" + token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import spacy as spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"tagger\", \"ner\", \"entity_ruler\"])\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text.lower() for token in doc]\n",
    "def normalize(text):\n",
    "    \"\"\"Resolve different type of unicode encodings.\"\"\"\n",
    "    return unicodedata.normalize(\"NFD\", text)\n",
    "\n",
    "\n",
    "def prepare_answers(answers):\n",
    "    r = []\n",
    "    for single_answer in answers:\n",
    "        single_answer = normalize(single_answer)\n",
    "        single_answer = single_answer.lower().split(\" \")  # tokenize(single_answer)\n",
    "        r.append(single_answer)\n",
    "    return r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "an = [['<Table>', 'The', 'Walking', 'Dead', '(', 'season', '8', ')', ':', 'Critical', 'reception', 'by', 'episode', '<Tr>', '<Td>', '<Ul>', '<Li>', 'Season', '8', '(', '2017', '--', '18', ')', ':', 'Percentage', 'of', 'positive', 'reviews', 'tracked', 'by', 'the', 'website', 'Rotten', 'Tomatoes', '</Li>', '</Ul>', '</Td>', '</Tr>', '</Table>'], [True, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True]]\n",
    "#print(prepare_answers([' '.join(an[0])]))\n",
    "html_mask = an[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Season 8 ( 2017 -- 18 ) : Percentage of positive reviews tracked by the website Rotten Tomatoes', [])]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from table_utils.utils import *\n",
    "\n",
    "soup = BeautifulSoup(' '.join(an[0]), 'html.parser')\n",
    "tmp = soup.find_all('table')\n",
    "rs = []\n",
    "for _ in tmp:\n",
    "    rs.append(_)\n",
    "\n",
    "for it, r in enumerate(rs):\n",
    "        heads = []\n",
    "        rows = []\n",
    "        replicate = {}\n",
    "        for i, t_row in enumerate(r.find_all('tr')):\n",
    "            if i == 0:\n",
    "                for h in t_row.find_all(['th', 'td']):\n",
    "                    h = remove_ref(h)\n",
    "                    if len(h.find_all('a')) > 0:\n",
    "                        tmp = (h.get_text(separator=\" \").strip(), process_link(h))\n",
    "                    else:\n",
    "                        tmp = (h.get_text(separator=\" \").strip(), [])\n",
    "                    assert len(tmp) and isinstance(tmp[0], str) and isinstance(tmp[1], list)\n",
    "                    heads.append(tmp)\n",
    "            else:\n",
    "                row = []\n",
    "                for h in t_row.find_all(['th', 'td']):\n",
    "                    col_idx = len(row)\n",
    "                    if col_idx in replicate:\n",
    "                        row.append(replicate[col_idx][1])\n",
    "                        replicate[col_idx][0] = replicate[col_idx][0] - 1\n",
    "                        if replicate[col_idx][0] == 0:\n",
    "                            del replicate[col_idx]\n",
    "                    h = remove_ref(h)\n",
    "                    if len(h.find_all('a')) > 0:\n",
    "                        tmp = (h.get_text(separator=\" \").strip(), process_link(h))\n",
    "                    else:\n",
    "                        tmp = (h.get_text(separator=\" \").strip(), [])\n",
    "                    if 'rowspan' in h.attrs:\n",
    "                        # Identify row span cases\n",
    "                        try:\n",
    "                            num = int(h['rowspan'])\n",
    "                            replicate[len(row)] = [num - 1, tmp]\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    assert len(tmp) and isinstance(tmp[0], str) and isinstance(tmp[1], list)\n",
    "                    row.append(tmp)\n",
    "    \n",
    "                    rows.append(row)\n",
    "        rows = rows[:20]\n",
    "        print(heads)\n",
    "        print(rows)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd8a621b835c679ba80c89dd5af99bc6f9ef5ca24dd94085a961837522b1bb13"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('py37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
